{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo\n",
    "#scrivere se il sito è offline (gestire response code diversi da 200)\n",
    "#qualcosa da aggiustare sull'inserimento della lingua\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from langdetect import detect, detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome(\"webdriver/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords base importate\n",
    "\n",
    "stop_words = get_stop_words('it')\n",
    "stop_words += get_stop_words('en')\n",
    "stop_words += get_stop_words('pt')\n",
    "stop_words += get_stop_words('es')\n",
    "stop_words += get_stop_words('de')\n",
    "stop_words += get_stop_words('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords personali aggiunte da me\n",
    "\n",
    "stop_words += [\"priority\",\"target\",\"events\",\"eventname\",\"flavors\",\"callback\",\"document\",\"stato\",\"legacy\",\"window\",\"visualizza\"]\n",
    "stop_words += [\"module\",\"article\",\"cette\",\"encore\",\"faire\",\"d’une\"]\n",
    "stop_words += [\"c'est\",\"della\",\"delle\"]\n",
    "stop_words += [\"settembre\",\t\"positivi\",\t\"giorno\",\t\"giorni\",\t\"agosto\",\t\"settimana\",\t\"progetto\",\t\"weeks\",\t\"evidenza\",\t\"siniscola\",\t\"della\",\t\"lucia\",\t\"santa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"sites_to_check.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>url_to_import</th>\n",
       "      <th>esito</th>\n",
       "      <th>lingua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>switchfan.org</td>\n",
       "      <td>switchfan.org</td>\n",
       "      <td>[['switch', 35], ['nintendo', 30], ['mario', 1...</td>\n",
       "      <td>[fr:0.9999963316595247]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contioutra.com</td>\n",
       "      <td>contioutra.com</td>\n",
       "      <td>[['conti', 15], ['outra', 13], ['filmes', 6], ...</td>\n",
       "      <td>[pt:0.999997725359873]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ricordinvaligia.it</td>\n",
       "      <td>ricordinvaligia.it</td>\n",
       "      <td>[['della', 12], ['settembre', 8], ['agosto', 8...</td>\n",
       "      <td>[it:0.9999948012100419]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sportlegnano.it</td>\n",
       "      <td>sportlegnano.it</td>\n",
       "      <td>[['serie', 36], ['legnano', 32], ['saronno', 2...</td>\n",
       "      <td>[it:0.9999965456651655]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geek-vintage.com</td>\n",
       "      <td>geek-vintage.com</td>\n",
       "      <td>[['classé', 11], ['article', 6], ['vidéo', 5],...</td>\n",
       "      <td>[fr:0.9999967650119764]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65728</th>\n",
       "      <td>nexofin.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65729</th>\n",
       "      <td>nexoseguros.com.br</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65730</th>\n",
       "      <td>nextext.us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65731</th>\n",
       "      <td>next-gamer.de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65732</th>\n",
       "      <td>next-post.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65733 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     site       url_to_import  \\\n",
       "0           switchfan.org       switchfan.org   \n",
       "1          contioutra.com      contioutra.com   \n",
       "2      ricordinvaligia.it  ricordinvaligia.it   \n",
       "3         sportlegnano.it     sportlegnano.it   \n",
       "4        geek-vintage.com    geek-vintage.com   \n",
       "...                   ...                 ...   \n",
       "65728         nexofin.com                 NaN   \n",
       "65729  nexoseguros.com.br                 NaN   \n",
       "65730          nextext.us                 NaN   \n",
       "65731       next-gamer.de                 NaN   \n",
       "65732       next-post.com                 NaN   \n",
       "\n",
       "                                                   esito  \\\n",
       "0      [['switch', 35], ['nintendo', 30], ['mario', 1...   \n",
       "1      [['conti', 15], ['outra', 13], ['filmes', 6], ...   \n",
       "2      [['della', 12], ['settembre', 8], ['agosto', 8...   \n",
       "3      [['serie', 36], ['legnano', 32], ['saronno', 2...   \n",
       "4      [['classé', 11], ['article', 6], ['vidéo', 5],...   \n",
       "...                                                  ...   \n",
       "65728                                              vuoto   \n",
       "65729                                              vuoto   \n",
       "65730                                              vuoto   \n",
       "65731                                              vuoto   \n",
       "65732                                              vuoto   \n",
       "\n",
       "                        lingua  \n",
       "0      [fr:0.9999963316595247]  \n",
       "1       [pt:0.999997725359873]  \n",
       "2      [it:0.9999948012100419]  \n",
       "3      [it:0.9999965456651655]  \n",
       "4      [fr:0.9999967650119764]  \n",
       "...                        ...  \n",
       "65728                      NaN  \n",
       "65729                      NaN  \n",
       "65730                      NaN  \n",
       "65731                      NaN  \n",
       "65732                      NaN  \n",
       "\n",
       "[65733 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sites_to_check_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spostare su file separato\n",
    "\n",
    "def removeHtmlTags(lista):\n",
    "    text = re.sub(\"\\<(.*?)\\>\",\"\",home_page_content)\n",
    "    return text\n",
    "\n",
    "\n",
    "def stripPunctuations(home_page_content):\n",
    "    \n",
    "    #bad_chars = \"?.,;:!\\'\"\n",
    "    bad_chars = [\"\\n\",\"\\t\",\"?\",\".\",\",\",\";\",\":\",\"!\",\"\\\\\",\"’\"]\n",
    "    for char in home_page_content:\n",
    "        if char in bad_chars:\n",
    "            home_page_content = home_page_content.replace(char,\"\")\n",
    "        \n",
    "    return home_page_content\n",
    "        \n",
    "\n",
    "\n",
    "def avoidStopWords(wordlist, stop_words):\n",
    "    for word in wordlist:\n",
    "        if word not in stop_words:\n",
    "            print(word)\n",
    "            list_saved_words.append(word)\n",
    "    return list_saved_words\n",
    "\n",
    "\n",
    "def removeWordsWithBadChars(content):\n",
    "    bad_list = [\"/\",\"(\",\")\", \"&\", \"{\",\"’\"]\n",
    "    bad_list += [\"}\", \"h1\", \"h2\", \"h3\",]\n",
    "    bad_list += [\"px\",\"_\",\"\\\\\",\"&\",\"@\", \"#\",\"-\",\"%\",\"'\"]\n",
    "    bad_list += [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\"]\n",
    "    print(bad_list)\n",
    "    for bad_char in bad_list:\n",
    "        for word in content:\n",
    "            if bad_char in word:\n",
    "                content.remove(word)\n",
    "    return content\n",
    "\n",
    "\n",
    "def CountFrequency(list_saved_words): \n",
    "    lista_2 = []\n",
    "    \n",
    "    for item in list_saved_words:\n",
    "        local_list = [item, list_saved_words.count(item)]\n",
    "        lista_2.append(local_list)\n",
    "    \n",
    "    return lista_2\n",
    "\n",
    "\n",
    "def removeDuplicates(list_saved_words):\n",
    "    unique_keywords = []\n",
    "    for item in list_saved_words:\n",
    "        if item not in unique_keywords:\n",
    "            unique_keywords.append(item)\n",
    "    return unique_keywords\n",
    "\n",
    "\n",
    "\n",
    "def sortList(sub_li): \n",
    "  \n",
    "    # key is set to sort using second element of  \n",
    "    # sublist lambda has been used \n",
    "    sub_li.sort(reverse=True, key = lambda x: x[1]) \n",
    "    return sub_li \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switchfan.org\n",
      "1\n",
      "già fatto\n",
      "contioutra.com\n",
      "2\n",
      "già fatto\n",
      "ricordinvaligia.it\n",
      "3\n",
      "già fatto\n",
      "sportlegnano.it\n",
      "4\n",
      "già fatto\n",
      "geek-vintage.com\n",
      "5\n",
      "già fatto\n",
      "http://fiorentinanews.com\n",
      "6\n",
      "non è un sito\n",
      "http://fiorentinanewswfwfe4v.com\n",
      "7\n",
      "non è un sito\n",
      "http://infocilento.it\n",
      "8\n",
      "non è un sito\n",
      "http://garotasquecurtemanimes.com.br\n",
      "9\n",
      "non è un sito\n",
      "http://bimbieviaggi.it\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "home_page_content = \"\"\n",
    "temp_keyword_frequencies = [] #serve per eliminare delle stop-words extra\n",
    "frequency_dict = {}\n",
    "index = 0\n",
    "all_words = [] #serve per eliminare delle stop-words extra, superato\n",
    "\n",
    "for url in df[\"url_to_import\"]:\n",
    "    print(url)\n",
    "    print(index + 1)\n",
    "    if \"http://\" not in url: #togliendo l'http dal df e poi dal file excel rendo visibile che l'url è già stato controllato\n",
    "        print(\"già fatto\")\n",
    "        index+=1\n",
    "        continue\n",
    "    else:\n",
    "        driver = webdriver.Chrome(\"webdriver/chromedriver\")\n",
    "        home_page_content_saved = []\n",
    "        \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            print(\"url preso\")\n",
    "            time.sleep(5) #non sono sicuro che sia necessario, il mio timore è che certe pagine non carichino per intero (numero parole sempre diverso)\n",
    "        except:\n",
    "            print(\"non è un sito\")\n",
    "            df[\"esito\"][index] = \"error\"\n",
    "            index+=1\n",
    "            continue\n",
    "            \n",
    "        home_page_content = driver.find_element_by_tag_name('body').text\n",
    "        home_page_content = str(home_page_content)\n",
    "        print(home_page_content[:50])\n",
    "        home_page_language = detect_langs(home_page_content)\n",
    "        df[\"lingua\"][index] = home_page_language\n",
    "        print(home_page_language)\n",
    "\n",
    "        home_page_content = home_page_content.lower()\n",
    "        home_page_content = removeHtmlTags(home_page_content)\n",
    "        home_page_content = stripPunctuations(home_page_content)\n",
    "        home_page_content = home_page_content.split(\" \")\n",
    "        #home_page_content diventa lista\n",
    "\n",
    "\n",
    "        for word in home_page_content:\n",
    "            if len(word)> 4 and len(word)< 20: \n",
    "                home_page_content_saved.append(word)\n",
    "                home_page_content = home_page_content_saved\n",
    "\n",
    "        #togliamo parole con bad_char\n",
    "        home_page_content = removeWordsWithBadChars(home_page_content)\n",
    "        #all_words += home_page_content\n",
    "\n",
    "        #calcoliamo la frequenza, ma siamo sempre in una lista\n",
    "        home_page_content = CountFrequency(home_page_content)\n",
    "\n",
    "        #togliamo le keyword che sono state usate una volta sola\n",
    "        temp_keyword_frequencies = []\n",
    "\n",
    "        for item in home_page_content:\n",
    "            if item[1] >= 2:\n",
    "                temp_keyword_frequencies.append(item)\n",
    "            home_page_content = temp_keyword_frequencies\n",
    "\n",
    "        #sistemino per eliminare un po' di cripto-stopwords\n",
    "        frequent_keywords = []\n",
    "\n",
    "        for item in home_page_content:\n",
    "            if item[1] >= 4:\n",
    "                frequent_keywords.append(item)\n",
    "        #print(frequent_keywords)\n",
    "\n",
    "\n",
    "        #togliamo i duplicati\n",
    "        home_page_content = removeDuplicates(home_page_content)\n",
    "        #print(home_page_content)   \n",
    "\n",
    "        #ordiniamo\n",
    "        home_page_content = sortList(home_page_content)\n",
    "        print(\"lunghezza finale\")\n",
    "        print(len(home_page_content))\n",
    "        home_page_content = str(home_page_content) #prima di inserire i valori sul foglio excel trasformiamo in stringa\n",
    "\n",
    "        df[\"esito\"][index] = home_page_content\n",
    "        df[\"url_to_import\"][index] = df[\"url_to_import\"][index].replace(\"http://\",\"\")\n",
    "        index += 1\n",
    "        driver.close()\n",
    "\n",
    "    #finalmente si trasforma tutto in dizionario\n",
    "    #il dizionario ha come key il sito, come value il mega-listone di keyword+frequency     \n",
    "    #frequency_dict[url] = home_page_content\n",
    "\n",
    "\n",
    "\n",
    "#si ricomincia da capo con un nuovo sito\n",
    "    \n",
    "\n",
    "    \n",
    "#print(frequency_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"sites_to_check.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(\"sites_to_check_sbagliato.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminare stopwords extra\n",
    "from pandas import DataFrame\n",
    "#df_all_words = DataFrame(frequent_keywords)\n",
    "df_all_words\n",
    "df_all_words.to_excel(\"frequent_keywords.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
