{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo\n",
    "#scrivere se il sito è offline (gestire response code diversi da 200)\n",
    "#qualcosa da aggiustare sull'inserimento della lingua\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from langdetect import detect, detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome(\"webdriver/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords base importate\n",
    "\n",
    "stop_words = get_stop_words('it')\n",
    "stop_words += get_stop_words('en')\n",
    "stop_words += get_stop_words('pt')\n",
    "stop_words += get_stop_words('es')\n",
    "stop_words += get_stop_words('de')\n",
    "stop_words += get_stop_words('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords personali aggiunte da me\n",
    "\n",
    "stop_words += [\"priority\",\"target\",\"events\",\"eventname\",\"flavors\",\"callback\",\"document\",\"stato\",\"legacy\",\"window\",\"visualizza\"]\n",
    "stop_words += [\"module\",\"article\",\"cette\",\"encore\",\"faire\",\"d’une\"]\n",
    "stop_words += [\"c'est\",\"della\",\"delle\"]\n",
    "stop_words += [\"settembre\",\t\"positivi\",\t\"giorno\",\t\"giorni\",\t\"agosto\",\t\"settimana\",\t\"progetto\",\t\"weeks\",\t\"evidenza\",\t\"siniscola\",\t\"della\",\t\"lucia\",\t\"santa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"sites_to_check.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>url_to_import</th>\n",
       "      <th>esito</th>\n",
       "      <th>lingua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>switchfan.org</td>\n",
       "      <td>switchfan.org</td>\n",
       "      <td>[['switch', 35], ['nintendo', 30], ['mario', 1...</td>\n",
       "      <td>[fr:0.9999963316595247]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contioutra.com</td>\n",
       "      <td>contioutra.com</td>\n",
       "      <td>[['conti', 15], ['outra', 13], ['filmes', 6], ...</td>\n",
       "      <td>[pt:0.999997725359873]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ricordinvaligia.it</td>\n",
       "      <td>ricordinvaligia.it</td>\n",
       "      <td>[['della', 12], ['settembre', 8], ['agosto', 8...</td>\n",
       "      <td>[it:0.9999948012100419]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sportlegnano.it</td>\n",
       "      <td>sportlegnano.it</td>\n",
       "      <td>[['serie', 36], ['legnano', 32], ['saronno', 2...</td>\n",
       "      <td>[it:0.9999965456651655]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geek-vintage.com</td>\n",
       "      <td>geek-vintage.com</td>\n",
       "      <td>[['classé', 11], ['article', 6], ['vidéo', 5],...</td>\n",
       "      <td>[fr:0.9999967650119764]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65728</th>\n",
       "      <td>nexofin.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65729</th>\n",
       "      <td>nexoseguros.com.br</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65730</th>\n",
       "      <td>nextext.us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65731</th>\n",
       "      <td>next-gamer.de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65732</th>\n",
       "      <td>next-post.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuoto</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65733 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     site       url_to_import  \\\n",
       "0           switchfan.org       switchfan.org   \n",
       "1          contioutra.com      contioutra.com   \n",
       "2      ricordinvaligia.it  ricordinvaligia.it   \n",
       "3         sportlegnano.it     sportlegnano.it   \n",
       "4        geek-vintage.com    geek-vintage.com   \n",
       "...                   ...                 ...   \n",
       "65728         nexofin.com                 NaN   \n",
       "65729  nexoseguros.com.br                 NaN   \n",
       "65730          nextext.us                 NaN   \n",
       "65731       next-gamer.de                 NaN   \n",
       "65732       next-post.com                 NaN   \n",
       "\n",
       "                                                   esito  \\\n",
       "0      [['switch', 35], ['nintendo', 30], ['mario', 1...   \n",
       "1      [['conti', 15], ['outra', 13], ['filmes', 6], ...   \n",
       "2      [['della', 12], ['settembre', 8], ['agosto', 8...   \n",
       "3      [['serie', 36], ['legnano', 32], ['saronno', 2...   \n",
       "4      [['classé', 11], ['article', 6], ['vidéo', 5],...   \n",
       "...                                                  ...   \n",
       "65728                                              vuoto   \n",
       "65729                                              vuoto   \n",
       "65730                                              vuoto   \n",
       "65731                                              vuoto   \n",
       "65732                                              vuoto   \n",
       "\n",
       "                        lingua  \n",
       "0      [fr:0.9999963316595247]  \n",
       "1       [pt:0.999997725359873]  \n",
       "2      [it:0.9999948012100419]  \n",
       "3      [it:0.9999965456651655]  \n",
       "4      [fr:0.9999967650119764]  \n",
       "...                        ...  \n",
       "65728                      NaN  \n",
       "65729                      NaN  \n",
       "65730                      NaN  \n",
       "65731                      NaN  \n",
       "65732                      NaN  \n",
       "\n",
       "[65733 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sites_to_check_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spostare su file separato\n",
    "\n",
    "def removeHtmlTags(lista):\n",
    "    text = re.sub(\"\\<(.*?)\\>\",\"\",home_page_content)\n",
    "    return text\n",
    "\n",
    "\n",
    "def stripPunctuations(home_page_content):\n",
    "    \n",
    "    #bad_chars = \"?.,;:!\\'\"\n",
    "    bad_chars = [\"\\n\",\"\\t\",\"?\",\".\",\",\",\";\",\":\",\"!\",\"\\\\\",\"’\"]\n",
    "    for char in home_page_content:\n",
    "        if char in bad_chars:\n",
    "            home_page_content = home_page_content.replace(char,\"\")\n",
    "        \n",
    "    return home_page_content\n",
    "        \n",
    "\n",
    "\n",
    "def avoidStopWords(wordlist, stop_words):\n",
    "    for word in wordlist:\n",
    "        if word not in stop_words:\n",
    "            print(word)\n",
    "            list_saved_words.append(word)\n",
    "    return list_saved_words\n",
    "\n",
    "\n",
    "def removeWordsWithBadChars(content):\n",
    "    bad_list = [\"/\",\"(\",\")\", \"&\", \"{\",\"’\"]\n",
    "    bad_list += [\"}\", \"h1\", \"h2\", \"h3\",]\n",
    "    bad_list += [\"px\",\"_\",\"\\\\\",\"&\",\"@\", \"#\",\"-\",\"%\",\"'\"]\n",
    "    bad_list += [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\"]\n",
    "    for bad_char in bad_list:\n",
    "        for word in content:\n",
    "            if bad_char in word:\n",
    "                content.remove(word)\n",
    "    return content\n",
    "\n",
    "\n",
    "def CountFrequency(list_saved_words): \n",
    "    lista_2 = []\n",
    "    \n",
    "    for item in list_saved_words:\n",
    "        local_list = [item, list_saved_words.count(item)]\n",
    "        lista_2.append(local_list)\n",
    "    \n",
    "    return lista_2\n",
    "\n",
    "\n",
    "def removeDuplicates(list_saved_words):\n",
    "    unique_keywords = []\n",
    "    for item in list_saved_words:\n",
    "        if item not in unique_keywords:\n",
    "            unique_keywords.append(item)\n",
    "    return unique_keywords\n",
    "\n",
    "\n",
    "\n",
    "def sortList(sub_li): \n",
    "  \n",
    "    # key is set to sort using second element of  \n",
    "    # sublist lambda has been used \n",
    "    sub_li.sort(reverse=True, key = lambda x: x[1]) \n",
    "    return sub_li \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def elaborate_web_page(url, df):\n",
    "    home_page_content = \"\"\n",
    "    temp_keyword_frequencies = [] #serve per eliminare delle stop-words extra\n",
    "    frequency_dict = {}\n",
    "    all_words = [] #serve per eliminare delle stop-words extra, superato \n",
    "    print(url)\n",
    "    \n",
    "    if \"http://\" not in url: #togliendo l'http dal df e poi dal file excel rendo visibile che l'url è già stato controllato\n",
    "        print(\"già fatto\")\n",
    "        return\n",
    "    else:\n",
    "        driver = webdriver.Chrome(\"webdriver/chromedriver\")\n",
    "        home_page_content_saved = []\n",
    "        \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            print(\"url preso\")\n",
    "            time.sleep(5) #non sono sicuro che sia necessario, il mio timore è che certe pagine non carichino per intero (numero parole sempre diverso)\n",
    "        except:\n",
    "            print(\"non è un sito\")\n",
    "            df[\"esito\"][index] = \"error\"\n",
    "            return\n",
    "            \n",
    "        home_page_content = driver.find_element_by_tag_name('body').text\n",
    "        home_page_content = str(home_page_content)\n",
    "        print(home_page_content[:50])\n",
    "        home_page_language = detect_langs(home_page_content)\n",
    "        df[\"lingua\"][url] = home_page_language\n",
    "        print(home_page_language)\n",
    "        print(df[:10])\n",
    "\n",
    "        home_page_content = home_page_content.lower()\n",
    "        home_page_content = removeHtmlTags(home_page_content)\n",
    "        home_page_content = stripPunctuations(home_page_content)\n",
    "        home_page_content = home_page_content.split(\" \")\n",
    "        #home_page_content diventa lista\n",
    "\n",
    "\n",
    "        for word in home_page_content:\n",
    "            if len(word)> 4 and len(word)< 20: \n",
    "                home_page_content_saved.append(word)\n",
    "                home_page_content = home_page_content_saved\n",
    "\n",
    "        #togliamo parole con bad_char\n",
    "        home_page_content = removeWordsWithBadChars(home_page_content)\n",
    "        #all_words += home_page_content\n",
    "\n",
    "        #calcoliamo la frequenza, ma siamo sempre in una lista\n",
    "        home_page_content = CountFrequency(home_page_content)\n",
    "\n",
    "        #togliamo le keyword che sono state usate una volta sola\n",
    "        temp_keyword_frequencies = []\n",
    "\n",
    "        for item in home_page_content:\n",
    "            if item[1] >= 2:\n",
    "                temp_keyword_frequencies.append(item)\n",
    "            home_page_content = temp_keyword_frequencies\n",
    "\n",
    "        #sistemino per eliminare un po' di cripto-stopwords\n",
    "        frequent_keywords = []\n",
    "\n",
    "        for item in home_page_content:\n",
    "            if item[1] >= 4:\n",
    "                frequent_keywords.append(item)\n",
    "        #print(frequent_keywords)\n",
    "\n",
    "\n",
    "        #togliamo i duplicati\n",
    "        home_page_content = removeDuplicates(home_page_content)\n",
    "        #print(home_page_content)   \n",
    "\n",
    "        #ordiniamo\n",
    "        home_page_content = sortList(home_page_content)\n",
    "        print(\"lunghezza finale: \"+len(home_page_content))\n",
    "        home_page_content = str(home_page_content) #prima di inserire i valori sul foglio excel trasformiamo in stringa\n",
    "\n",
    "        df[\"esito\"][url] = home_page_content\n",
    "        df[\"url_to_import\"][url] = df[\"url_to_import\"][url].replace(\"http://\",\"\")\n",
    "        driver.close()\n",
    "\n",
    "    #finalmente si trasforma tutto in dizionario\n",
    "    #il dizionario ha come key il sito, come value il mega-listone di keyword+frequency     \n",
    "    #frequency_dict[url] = home_page_content\n",
    "\n",
    "\n",
    "\n",
    "#si ricomincia da capo con un nuovo sito\n",
    "    \n",
    "\n",
    "    \n",
    "#print(frequency_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switchfan.org\n",
      "già fatto\n",
      "contioutra.com\n",
      "già fatto\n",
      "ricordinvaligia.it\n",
      "già fatto\n",
      "sportlegnano.it\n",
      "già fatto\n",
      "geek-vintage.com\n",
      "già fatto\n",
      "http://fiorentinanews.com\n",
      "url preso\n",
      "Il rispetto della tua privacy è la nostra priorità\n",
      "[it:0.9999957251535561]\n",
      "                            site                         url_to_import  \\\n",
      "0                  switchfan.org                         switchfan.org   \n",
      "1                 contioutra.com                        contioutra.com   \n",
      "2             ricordinvaligia.it                    ricordinvaligia.it   \n",
      "3                sportlegnano.it                       sportlegnano.it   \n",
      "4               geek-vintage.com                      geek-vintage.com   \n",
      "5             fiorentinanews.com             http://fiorentinanews.com   \n",
      "6        fiorentinaneewfwews.com      http://fiorentinanewswfwfe4v.com   \n",
      "7                 infocilento.it                 http://infocilento.it   \n",
      "8  garotasquecurtemanimes.com.br  http://garotasquecurtemanimes.com.br   \n",
      "9                bimbieviaggi.it                http://bimbieviaggi.it   \n",
      "\n",
      "                                               esito                   lingua  \n",
      "0  [['switch', 35], ['nintendo', 30], ['mario', 1...  [fr:0.9999963316595247]  \n",
      "1  [['conti', 15], ['outra', 13], ['filmes', 6], ...   [pt:0.999997725359873]  \n",
      "2  [['della', 12], ['settembre', 8], ['agosto', 8...  [it:0.9999948012100419]  \n",
      "3  [['serie', 36], ['legnano', 32], ['saronno', 2...  [it:0.9999965456651655]  \n",
      "4  [['classé', 11], ['article', 6], ['vidéo', 5],...  [fr:0.9999967650119764]  \n",
      "5                                              vuoto                      NaN  \n",
      "6                                              vuoto                      NaN  \n",
      "7                                              vuoto                      NaN  \n",
      "8                                              vuoto                      NaN  \n",
      "9                                              vuoto                      NaN  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'home_page_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-164ac333bf84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0melaborate_web_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-65c17b38a407>\u001b[0m in \u001b[0;36melaborate_web_page\u001b[1;34m(url, df)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mhome_page_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhome_page_content\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mhome_page_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremoveHtmlTags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhome_page_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mhome_page_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstripPunctuations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhome_page_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mhome_page_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhome_page_content\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-8302ad4e4c45>\u001b[0m in \u001b[0;36mremoveHtmlTags\u001b[1;34m(lista)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremoveHtmlTags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\<(.*?)\\>\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhome_page_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'home_page_content' is not defined"
     ]
    }
   ],
   "source": [
    "urls = df[\"url_to_import\"]\n",
    "\n",
    "for url in urls:\n",
    "    elaborate_web_page(url, df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it:0.9999957251535561]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'http://fiorentinanews.com'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3f35db8f7ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lingua\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"site\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4404\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4405\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4406\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'http://fiorentinanews.com'"
     ]
    }
   ],
   "source": [
    "print(df[\"lingua\"][url])\n",
    "print(df[\"site\"][url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"sites_to_check.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(\"sites_to_check_sbagliato.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminare stopwords extra\n",
    "from pandas import DataFrame\n",
    "#df_all_words = DataFrame(frequent_keywords)\n",
    "df_all_words\n",
    "df_all_words.to_excel(\"frequent_keywords.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
